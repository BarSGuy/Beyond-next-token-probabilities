# wandb sweep ./sweeps/LOS/DC/pythia_12_BookMIA.yaml
# conda activate hellucinations3 && CUDA_VISIBLE_DEVICES=2 wandb agent guybs/LOS-Net/pip01m6c


# sleep 10800; cd /home/guy_b/LOS-Net && conda activate hellucinations3 && for i in 3 4 5; do CUDA_VISIBLE_DEVICES=$i wandb agent guybs/LOS-Net/eprubvp5 & done

program: ./main.py  # Replace with the actual script name

method: grid  # Using grid search to exhaustively find the best hyperparameters

metric:
  name: best_val_AUC  # Using validation AUC to evaluate performance
  goal: maximize  # We want to maximize the validation AUC

parameters:
  # Training settings
  num_epochs:
    values: [500]
  batch_size:
    values: [64]
  patience:
    values: [30]
  seed:
    values: [0, 1, 2]

  # Model architecture
  probe_model:
    values: ["LOS-Net", "ATP_R_Transf", "ATP_R_MLP"]
  hidden_dim:
    values: [64, 128]
  num_layers:
    values: [1, 2]
  heads:
    values: [8]
  dropout:
    values: [0, 0.3, 0.5]
  pool:
    values: ["cls"]

  # Optimization settings
  lr:
    values: [1e-4]
  weight_decay:
    values: [0, 0.001]

  # Dataset and input settings
  train_dataset:
    values: ["BookMIA_128"]
  input_type:
    values: ["LOS"]
  input_output_type:
    values: ["input"]
  topk_preprocess:
    values: [1_000]
  topk_dim:
    values: [1_000]
  rank_encoding:
    values: ["scale_encoding"]
  num_workers:
    values: [4]
  pin_memory:
    values: [1]

  # Cross-validation
  num_folds:
    values: [5]
  fold_to_run:
    values: [0]

  # Paths
  best_model_path:
    values: ["saved_models"]
  base_pre_processed_data_dir:
    values: ['/home/guy_b/LOS-Net/pre_processed_data']

  # Model type
  LLM:
    values: ['EleutherAI/pythia-12b']

  # Hardware settings
  cuda_idx:
    values: [0]
